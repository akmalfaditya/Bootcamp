# Log File Exploration Guide

This document helps you explore and understand the structured logging output generated by the Structured Logging Demo application.

## Log File Locations

After running the application, you'll find log files in the `logs/` directory:

### Serilog Generated Files
- `application-YYYY-MM-DD.log` - Text format logs with structured templates
- `application-json-YYYY-MM-DD.log` - JSON format logs for analysis tools

### NLog Generated Files (when NLog is configured)
- `nlog-YYYY-MM-DD.log` - Detailed application logs with ASP.NET Core context
- `nlog-json-YYYY-MM-DD.log` - JSON structured logs with rich metadata
- `nlog-errors-YYYY-MM-DD.log` - Error-specific logs for monitoring
- `nlog-performance-YYYY-MM-DD.log` - Performance-related logs

## Exploring Log Content

### 1. Application Startup Logs
Look for these patterns when the application starts:
```
[2025-06-02 11:49:47.231 +07:00] [INF] [] Application starting in Development mode at 06/02/2025 04:49:47 {"MachineName": "SE-157", "ProcessId": 2300, "ThreadId": 1}
```

**Key Learning Points:**
- Timestamp with timezone information
- Log level (INF = Information)
- Structured properties in JSON format
- Environment context (machine name, process ID)

### 2. HTTP Request Logs
When you make API calls, look for request logging:
```
[2025-06-02 11:50:15.123 +07:00] [INF] [Microsoft.AspNetCore.Hosting.Diagnostics] HTTP GET /api/users/1 responded 200 in 45.2341 ms {"RequestHost": "localhost:5294", "RequestScheme": "http", "UserAgent": "Mozilla/5.0...", "ClientIP": "::1", "CorrelationId": "abc-123-def"}
```

**Key Learning Points:**
- HTTP method and path
- Response status code and timing
- Client context (IP, User Agent)
- Unique correlation ID for tracing

### 3. Business Operation Logs
When testing the API endpoints, look for business logic logging:

#### User Authentication
```
[2025-06-02 11:50:30.456 +07:00] [INF] [StructuredLogging.Demo.Services.UserService] User login attempt for john.doe from 192.168.1.100 at 2025-06-02T04:50:30Z {"Username": "john.doe", "ClientIP": "192.168.1.100", "CorrelationId": "xyz-789-abc"}
```

#### Order Processing
```
[2025-06-02 11:51:00.789 +07:00] [INF] [StructuredLogging.Demo.Services.OrderService] Order 12345 created successfully for user 67890 with total amount $150.75 {"OrderId": 12345, "UserId": 67890, "TotalAmount": 150.75, "ItemCount": 2}
```

#### Performance Monitoring
```
[2025-06-02 11:51:15.012 +07:00] [INF] [StructuredLogging.Demo.Controllers.OrderController] Order creation completed in 1234ms for UserId: 67890 {"ElapsedMilliseconds": 1234, "UserId": 67890, "CorrelationId": "def-456-ghi"}
```

### 4. Error Handling Logs
When testing error scenarios, look for detailed error context:
```
[2025-06-02 11:52:00.345 +07:00] [ERR] [StructuredLogging.Demo.Services.UserService] User authentication failed for john.doe from 192.168.1.100 {"Username": "john.doe", "ClientIP": "192.168.1.100", "Reason": "InvalidPassword", "CorrelationId": "ghi-789-jkl"}
```

## Testing Scenarios

### Scenario 1: User Authentication Flow
1. Use the API test file (`api-tests.http`) to test login
2. Check logs for:
   - Login attempt logging with user context
   - Security event tracking
   - Performance timing
   - Correlation ID consistency

### Scenario 2: Order Processing Workflow
1. Create an order using the API
2. Process payment
3. Process shipping
4. Check logs for:
   - Business operation tracking
   - State change logging
   - Error handling (if validation fails)
   - Cross-service correlation

### Scenario 3: Error Conditions
1. Try invalid login credentials
2. Create order with invalid data
3. Access non-existent resources
4. Check logs for:
   - Structured error information
   - Context preservation
   - Client information tracking

## JSON Log Analysis

For structured analysis, examine the JSON logs:

```json
{
  "timestamp": "2025-06-02 11:49:47.231",
  "level": "INFO",
  "message": "Order created successfully",
  "properties": {
    "OrderId": 12345,
    "UserId": 67890,
    "TotalAmount": 150.75,
    "CorrelationId": "abc-123-def",
    "MachineName": "SE-157",
    "ProcessId": 2300,
    "ThreadId": 1
  }
}
```

**Analysis Points:**
- Easy to query by specific properties
- Maintains data types (numbers, strings, booleans)
- Includes context metadata automatically
- Perfect for log aggregation tools

## PowerShell Commands for Log Analysis

### View Recent Logs
```powershell
# View last 20 lines from application log
Get-Content "logs\application-$(Get-Date -Format 'yyyy-MM-dd').log" -Tail 20

# Monitor logs in real-time
Get-Content "logs\application-$(Get-Date -Format 'yyyy-MM-dd').log" -Wait -Tail 10
```

### Search for Specific Patterns
```powershell
# Find all login attempts
Select-String -Path "logs\application-*.log" -Pattern "login attempt"

# Find all errors
Select-String -Path "logs\application-*.log" -Pattern "\[ERR\]"

# Find logs for specific user
Select-String -Path "logs\application-*.log" -Pattern "UserId.*67890"
```

### Analyze JSON Logs
```powershell
# Parse JSON logs for analysis
Get-Content "logs\application-json-$(Get-Date -Format 'yyyy-MM-dd').log" | 
  ForEach-Object { ConvertFrom-Json $_ } | 
  Where-Object { $_.level -eq "ERROR" } | 
  Select-Object timestamp, message, properties
```

## Best Practices Demonstrated

### 1. Structured Properties
- ✅ Use meaningful property names: `{Username}`, `{OrderId}`
- ✅ Include context: timestamps, correlation IDs
- ✅ Preserve data types: numbers as numbers, not strings

### 2. Log Levels
- ✅ **Information**: Business events, successful operations
- ✅ **Warning**: Unexpected but handled conditions
- ✅ **Error**: Errors that don't stop the application
- ✅ **Debug**: Detailed information for development

### 3. Context Preservation
- ✅ Correlation IDs for request tracing
- ✅ User context across operations
- ✅ Performance timing information
- ✅ Client information (IP, User Agent)

### 4. Security Considerations
- ✅ Never log passwords or sensitive data
- ✅ Log security events (login attempts, failures)
- ✅ Include client context for security analysis
- ✅ Use structured format for security monitoring

## Next Steps

1. **Run the Application**: Use `dotnet run` in the project directory
2. **Test the APIs**: Use the provided `api-tests.http` file
3. **Monitor Logs**: Watch the log files as you test different scenarios
4. **Analyze Patterns**: Look for the structured logging patterns described above
5. **Experiment**: Try different API calls and observe the logging output

## Integration with Log Analysis Tools

The JSON formatted logs are perfect for:
- **ELK Stack** (Elasticsearch, Logstash, Kibana)
- **Splunk** for enterprise log analysis
- **Azure Application Insights** for cloud monitoring
- **AWS CloudWatch** for AWS deployments
- **Custom analysis tools** using the structured JSON format

---

**Remember**: Structured logging is about making your logs machine-readable while keeping them human-friendly. The goal is to enable powerful analysis and monitoring while maintaining clarity for developers.
